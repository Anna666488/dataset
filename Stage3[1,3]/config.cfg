[DataSetHG]
training_txt_file: 'H:/xiao/Data_new_7.16/Final_datasets/2020.7.22_/Data_final_train.txt'


img_directory: 'H:/xiao/Data_new_7.16/Final_datasets/2020.7.22_/Data'


#图像数据和关键点热图大小是不能够更改的，在github中描述的
img_size: 256
hm_size: 64
num_joints: 16
remove_joints: None
joint_list = ['r_b_paw','r_b_knee','r_b_elbow','l_b_elbow','l_b_knee','l_b_paw',
             'tail','withers','head','nose','r_f_paw','r_f_knee','r_f_elbow','l_f_elbow','l_f_knee','l_f_paw']
point_pairs = [[0, 1], [1, 2], [2, 6], [3, 6], [4, 3], [5,4],[6,7],[10,11],[11,12],[12,7],[7,13],[13,14],[14,15],[8,7],[9,8],[15,14]]

[Network]
name:  'hg_network'#这里的名字从何而来? 目前看到：是因为每个epoch后保存模型的名字。
#本项目原来参数值：'hg_refined_200'
nFeats: 256  #为什么要设计一个这个参数？因为是设定的一个维度大小
nStacks: 3
nModules: 1 #没用的参数，其实不是没用，在用到attention机制时是利用到这个了。
tiny: False
nLow: 4
dropout_rate: 0.2
mcam: False   #多上下文注意力机制
[Train]
batch_size: 8
#8
#默认值：4 #因为我的计算资源有限，我将batch_size改大点，要不迭代太多次
#以下我只是先调通，所以都改小
nEpochs:  100

epoch_size: 445

learning_rate: 0.00025
learning_rate_decay: 0.96
decay_step: 2000           #这个根据epoch和batch_size要进行修改
weighted_loss: False  #这个是指一种新的损失么？
[Validation]
valid_iteration: 5  #10  此参数光在这里改是不行的，还需要在代码中改


[Saver]
log_dir_train: 'H:/xiao/Data_new_7.16/Stage_3_[1,3]/save_log_train_3/'
log_dir_test: 'H:/xiao/Data_new_7.16/Stage_3_[1,3]/save_log_test_3/'

saver_step: 230

saver_directory: 'D:/home_program/xiangmu_1/save_model/'  #这里并未按照我设定的路径去存储
